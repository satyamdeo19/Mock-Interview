# ğŸš€ AI Mock Interview Platform

A multimodal AI-powered system that evaluates candidates through video, audio, text, and resume analysis to generate real-time feedback, behavioral insights, and detailed scoring reportsâ€”simulating a real HR interview panel.

![License](https://img.shields.io/badge/license-MIT-blue.svg)
![Python](https://img.shields.io/badge/python-3.10+-blue.svg)
![Node](https://img.shields.io/badge/node-18+-green.svg)

---

## ğŸ”¥ Key Highlights

### ğŸ¥ Multimodal Input
- Real-time webcam video capture
- Live audio recording + transcription
- NLP-based answer quality evaluation
- AI-powered resume parsing

### ğŸ§  AI Interviewer
- Dynamically adjusts difficulty
- Domain-specific technical questions
- Behavior & tone-aware follow-ups

### ğŸ“Š Feedback Engine
- Confidence score analysis
- Communication clarity metrics
- Technical correctness evaluation
- Bias & filler-word detection
- Attitude, fluency, and delivery assessment

### ğŸ“ˆ Analytics & Reports
- SHAP explainability
- Skill-wise performance charts
- Strengthâ€“weakness summary
- PDF/JSON report export

---

## ğŸ—‚ï¸ Project Structure

```
.
â”œâ”€â”€ __venv/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ .env
â”‚   â”œâ”€â”€ benchmark_data.json
â”‚   â”œâ”€â”€ config.py
â”‚   â”œâ”€â”€ feature_config.json
â”‚   â”œâ”€â”€ feature_weights.json
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ process_session.py
â”‚   â”œâ”€â”€ question_generator.py
â”‚   â”œâ”€â”€ resume_parser.py
â”‚   â”œâ”€â”€ feature_engineering/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ multimodal_fusion.py
â”‚   â”‚   â””â”€â”€ video_aggregator.py
â”‚   â”œâ”€â”€ feature_extractors/
â”‚   â”‚   â”œâ”€â”€ audio_extractor.py
â”‚   â”‚   â”œâ”€â”€ text_extractor.py
â”‚   â”‚   â””â”€â”€ video_extractor.py
â”‚   â”œâ”€â”€ feedback_engine/
â”‚   â”‚   â”œâ”€â”€ feedback_generator.py
â”‚   â”‚   â”œâ”€â”€ predictor.py
â”‚   â”‚   â”œâ”€â”€ shap_analyzer.py
â”‚   â”‚   â””â”€â”€ weighted_scorer.py
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ human_aligned_model.joblib
â”‚   â”‚   â””â”€â”€ scaler.joblib
â”‚   â”œâ”€â”€ processed_features/
â”‚   â”œâ”€â”€ recordings/
â”‚   â”‚   â””â”€â”€ sessions/
â”‚   â”‚       â””â”€â”€ {session_id}/
â”‚   â”‚           â”œâ”€â”€ audio/
â”‚   â”‚           â”‚   â””â”€â”€ full_session.webm
â”‚   â”‚           â”œâ”€â”€ video/
â”‚   â”‚           â”‚   â”œâ”€â”€ chunk0.webm
â”‚   â”‚           â”‚   â””â”€â”€ chunkN.webm
â”‚   â”‚           â””â”€â”€ extracted_frames/
â”‚   â”œâ”€â”€ temp/
â”‚   â””â”€â”€ utils/
â”‚
â””â”€â”€ frontend/
    â”œâ”€â”€ public/
    â”œâ”€â”€ package.json
    â””â”€â”€ src/
        â”œâ”€â”€ App.jsx
        â”œâ”€â”€ components/
        â”œâ”€â”€ hooks/
        â”œâ”€â”€ services/
        â”œâ”€â”€ styles/
        â””â”€â”€ utils/
```

---

## âš™ï¸ System Requirements

### Backend
- Python 3.10+
- FFmpeg
- PyTorch / Transformers
- Joblib
- OpenCV

### Frontend
- Node.js 18+
- Browser with WebRTC support

### Hardware
- GPU recommended (for faster processing)
- Webcam + Microphone

---

## ğŸ”‘ Environment Variables

### Backend `.env`

Create `backend/.env` with the following:

```env
OPENAI_API_KEY=your_openai_api_key_here
MODEL_PATH=models/human_aligned_model.joblib
SCALER_PATH=models/scaler.joblib
TEMP_DIR=temp
RECORDINGS_DIR=recordings/sessions
```

### Frontend `.env` (Optional)

Create `frontend/.env` if needed:

```env
VITE_API_URL=http://localhost:8000
```

---

## ğŸ› ï¸ Installation & Setup

### Backend Setup

1. **Create Virtual Environment**

```bash
python -m venv __venv

# Activate virtual environment
# Linux/macOS:
source __venv/bin/activate

# Windows:
__venv\Scripts\activate
```

2. **Install Dependencies**

```bash
cd backend
pip install -r requirements.txt
```

3. **Start Backend Server**

```bash
uvicorn main:app --reload
```

Backend will run at: **http://localhost:8000**

---

### Frontend Setup

1. **Install Dependencies**

```bash
cd frontend
npm install
```

2. **Start Development Server**

```bash
npm run dev
```

Frontend will run at: **http://localhost:5173**

---
### Installation Issues: Use this venv folder
Link:
## ğŸš¦ API Endpoints

### ğŸ”¹ Session Handling

| Method | Endpoint | Description |
|--------|----------|-------------|
| POST | `/start_session` | Create new interview session |
| POST | `/upload_audio` | Upload audio chunk |
| POST | `/upload_video` | Upload video chunk |
| POST | `/process_session` | Run full processing pipeline |
| GET | `/get_feedback/{session_id}` | Retrieve final results |

### ğŸ”¹ Resume Parsing

| Method | Endpoint | Description |
|--------|----------|-------------|
| POST | `/parse_resume` | Parse and extract resume data |

---

## ğŸ§  Processing Pipeline

### 1ï¸âƒ£ **Capture**
- Video chunks â†’ WebRTC
- Audio stream â†’ WebM
- Transcript â†’ Whisper
- Resume PDF â†’ Parser

### 2ï¸âƒ£ **Extract Features**
- **Video**: EAR (eye aspect ratio), MAR (mouth aspect ratio), brow raise, smile intensity
- **Audio**: MFCC, pitch, speed, energy
- **Text**: Coherence, sentiment, verbosity
- **Resume**: Skills, education, experience

### 3ï¸âƒ£ **Multimodal Fusion**
`multimodal_fusion.py` merges all feature vectors into a unified representation.

### 4ï¸âƒ£ **Prediction**
ML model outputs:
- Confidence score
- Communication quality
- Delivery metrics
- Overall performance score

### 5ï¸âƒ£ **Feedback Generation**
`feedback_generator.py` produces:
- Strengths
- Weaknesses
- Actionable improvements
- SHAP explanatory charts
- Timeline graphs

---

## ğŸ“Š Generated Outputs

- âœ… JSON logs
- âœ… Full feature dump
- âœ… SHAP value visualizations
- âœ… Performance charts
- âœ… Summary text report
- âœ… Final interview score
- âœ… Step-by-step improvement suggestions

---

## ğŸ–¼ï¸ Architecture Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       Frontend (React)              â”‚
â”‚                                     â”‚
â”‚  â”œâ”€â”€ Webcam â†’ Video Chunks          â”‚
â”‚  â”œâ”€â”€ Mic â†’ Audio Chunks             â”‚
â”‚  â””â”€â”€ Text Answers                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       Backend (FastAPI)             â”‚
â”‚                                     â”‚
â”‚  â”œâ”€â”€ Video Extractor                â”‚
â”‚  â”œâ”€â”€ Audio Extractor                â”‚
â”‚  â”œâ”€â”€ Text Extractor                 â”‚
â”‚  â”œâ”€â”€ Resume Parser                  â”‚
â”‚  â”‚                                  â”‚
â”‚  â””â”€â”€ Multimodal Fusion              â”‚
â”‚      â”‚                              â”‚
â”‚      â””â”€â”€ ML Predictor               â”‚
â”‚          â”‚                          â”‚
â”‚          â””â”€â”€ Feedback Engine        â”‚
â”‚              â”‚                      â”‚
â”‚              â””â”€â”€ Report Generator   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ§© Tech Stack

### Frontend
- React
- WebRTC
- TailwindCSS
- Axios

### Backend
- FastAPI
- Whisper (Audio transcription)
- OpenCV (Video processing)
- NumPy, Pandas (Data processing)
- SHAP (Explainability)
- XGBoost / Custom ML models

---

## ğŸ¤ Contributing

We welcome contributions! Here's how you can help:

1. **Fork** the repository
2. Create a **feature branch** (`git checkout -b feature/amazing-feature`)
3. **Commit** your changes (`git commit -m 'Add some amazing feature'`)
4. **Push** to the branch (`git push origin feature/amazing-feature`)
5. Submit a **Pull Request**

---

## ğŸ“œ License

This project is licensed under the **MIT License** â€” free to use and modify.

---

## ğŸ“§ Contact & Support

For questions, issues, or feature requests, please open an issue on GitHub.

---

## ğŸŒŸ Star Us!

If you find this project helpful, please consider giving it a â­ on GitHub!

---

**Built with â¤ï¸ by the AI Interview Platform Team**
