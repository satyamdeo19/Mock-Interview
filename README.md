.

ğŸ“˜ AI Mock Interview System â€” README
ğŸš€ A Complete Multimodal AI Interview Evaluation System

Text + Audio + Video â†’ Behavioral Scoring â†’ SHAP Explainability â†’ Personalized Feedback

ğŸ§© Project Overview

This project is an AI-powered Mock Interview System that analyzes video, audio, and text responses to evaluate a candidate across 10 behavioral dimensions such as Confidence, Fluency, Engagement, Professionalism, Cognitive Complexity, etc.

It extracts over 120 multimodal features, performs feature engineering, fuses modalities using a weighted scoring model, and provides detailed, explainable interview feedback using SHAP.

The system consists of:

Backend: FastAPI + Python (feature extraction + scoring + model inference)

Frontend: React.js (webcam recording, dashboard, UI)

Machine Learning: RandomForest models trained on multimodal interview datasets

ğŸ“‚ Project Structure
____venv
â”œâ”€â”€ backend
â”‚
â”‚   â”œâ”€â”€ __pycache__
â”‚   â”œâ”€â”€ .env
â”‚   â”œâ”€â”€ benchmark_data.json
â”‚   â”œâ”€â”€ config.py
â”‚   â”œâ”€â”€ feature_config.json
â”‚   â”œâ”€â”€ feature_weights.json
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ process_session.py
â”‚   â”œâ”€â”€ question_generator.py
â”‚   â”œâ”€â”€ resume_parser.py
â”‚   â”œâ”€â”€ feature_engineering
â”‚   â”‚   â”œâ”€â”€ init.py
â”‚   â”‚   â”œâ”€â”€ multimodal_fusion.py
â”‚   â”‚   â””â”€â”€ video_aggregator.py
â”‚   â”œâ”€â”€ feature_extractors
â”‚   â”‚   â”œâ”€â”€ audio_extractor.py
â”‚   â”‚   â”œâ”€â”€ text_extractor.py
â”‚   â”‚   â””â”€â”€ video_extractor.py
â”‚   â”œâ”€â”€ feedback_engine
â”‚   â”‚   â”œâ”€â”€ feedback_generator.py
â”‚   â”‚   â”œâ”€â”€ predictor.py
â”‚   â”‚   â”œâ”€â”€ shap_analyzer.py
â”‚   â”‚   â””â”€â”€ weighted_scorer.py
â”‚   â”œâ”€â”€ feedback_results
â”‚   â”‚   â”œâ”€â”€ models
â”‚   â”‚   â”‚   â”œâ”€â”€ human_aligned_model.joblib
â”‚   â”‚   â”‚   â””â”€â”€ scaler.joblib
â”‚   â”‚   â””â”€â”€ processed_features
â”‚   â”œâ”€â”€ recordings
â”‚   â”‚   â””â”€â”€ sessions
â”‚   â”œâ”€â”€ temp
â”‚   â”‚   â””â”€â”€ visualization
â”‚   â”‚       â”œâ”€â”€ chart_generator.py
â”‚   â”‚       â””â”€â”€ report_builder.py
â”‚   â””â”€â”€ __init__.py
â””â”€â”€ frontend
    â”œâ”€â”€ node_modules
    â”œâ”€â”€ public
    â”œâ”€â”€ package-lock.json
    â”œâ”€â”€ package.json
    â”œâ”€â”€ src
    â”‚   â”œâ”€â”€ App.jsx
    â”‚   â”œâ”€â”€ components
    â”‚   â”œâ”€â”€ hooks
    â”‚   â”œâ”€â”€ services
    â”‚   â”œâ”€â”€ styles
    â”‚   â””â”€â”€ utils
    â””â”€â”€ README

âš™ï¸ System Requirements
Backend Requirements

Python 3.10+

FFmpeg (mandatory for audio/video processing)

pip 23+

Virtual environment (venv)

Requirements from requirement.txt

Frontend Requirements

Node.js 18+

npm or yarn

ğŸ› ï¸ Backend Setup
1ï¸âƒ£ Navigate to Backend Folder
cd backend

2ï¸âƒ£ Create Virtual Environment
python -m venv .venv

Activate venv

Windows

.venv\Scripts\activate


Linux/Mac

source .venv/bin/activate

3ï¸âƒ£ Install Dependencies

Make sure you have a requirements.txt file in backend.
Then run:

pip install -r requirements.txt

4ï¸âƒ£ Install FFmpeg

This is required for audio extraction and merging video chunks.

Windows:
Download from: https://www.gyan.dev/ffmpeg/builds/

Add FFmpeg bin/ path to your System PATH.

Linux

sudo apt install ffmpeg


Mac

brew install ffmpeg

5ï¸âƒ£ Create .env File

Inside /backend/.env:

GEMINI_API_KEY=YOUR_KEY_HERE


(Or leave blank to use template fallback question generator.)

6ï¸âƒ£ Run Backend Server
cd backend
uvicorn main:app --reload


You should see:

http://127.0.0.1:8000
Docs: http://127.0.0.1:8000/docs

ğŸ–¥ï¸ Frontend Setup
1ï¸âƒ£ Navigate to Frontend Folder
cd frontend

2ï¸âƒ£ Install Dependencies
npm install

3ï¸âƒ£ Run Frontend
npm start


Frontend runs on:

http://localhost:3000

ğŸ”„ End-to-End Flow
1. Upload Resume

Backend parses skills, projects, experience

Question generator (Gemini API or fallback)

2. Start Interview Session

Frontend:

Captures webcam video in chunks

Records full-session audio

Sends Q&A transcript to backend

3. Backend Pipeline

Text feature extraction

Audio feature extraction

Video feature extraction

Video feature aggregation

Multimodal feature fusion

Weighted scoring

SHAP explainability

Feedback report generation (JSON + visualizations)

4. Frontend Dashboard

Radar charts

Strengths & weaknesses

Improvement tips

Score breakdown

ğŸ“¦ Important Backend Directories
âœ” recordings/sessions/

Stores:

Video chunks

Full session audio

Transcript CSV/JSON

âœ” processed_features/

Stores:

audio_features.csv

video_features_raw.csv

video_features_aggregated.csv

text_features.csv

final_multimodal_features.csv

âœ” feedback_results/

Stores:

weighted_scores.json

feedback_report.json

visualizations (radar charts, bar charts)

model joblib files

ğŸ§® Key ML Components
âœ” Feature Extractors

feature_extractors/

audio_extractor.py

video_extractor.py

text_extractor.py

âœ” Feature Engineering

feature_engineering/

video_aggregator.py

multimodal_fusion.py

âœ” ML Models

feedback_engine/

predictor.py

weighted_scorer.py

shap_analyzer.py

feedback_generator.py

ğŸ“Š Models Included

Located in:

backend/feedback_results/models


Includes:

human_aligned_model.joblib

scaler.joblib

These models output:

Final score

10 dimension scores

SHAP explanations

ğŸ›‘ Common Issues
âŒ Video chunks not merging

â†’ Install FFmpeg
â†’ Add to PATH
â†’ Enable correct permissions

âŒ No radar_chart.png

â†’ Ensure static route is mapped
â†’ Save visualizations in:
feedback_results/<session_id>/visualizations

âŒ CORS errors

â†’ Add frontend URL to FastAPI CORS middleware

âŒ Gemini API failure

â†’ Falls back to template question generator automatically

ğŸ§ª Testing the Backend
Test resume upload
curl -X POST -F "file=@resume.pdf" http://127.0.0.1:8000/upload_resume

Test session creation
curl -X POST http://127.0.0.1:8000/api/session/create

Test feedback retrieval
curl http://127.0.0.1:8000/api/session/<session_id>/feedback

ğŸ“œ Scripts Summary
Module	Purpose
main.py	FastAPI routing, session orchestration
process_session.py	Full pipeline execution
audio_extractor.py	Extract 50+ audio features
video_extractor.py	468 landmark processing, head pose, facial metrics
text_extractor.py	NLP features, sentiment, filler ratio
video_aggregator.py	Frame â†’ session aggregation
multimodal_fusion.py	10-dimension fusion + final score
weighted_scorer.py	Weighted scoring model
shap_analyzer.py	SHAP explanations
feedback_generator.py	Natural language feedback
chart_generator.py	Radar charts, bar charts
report_builder.py	(Optional) PDF/HTML report builder
ğŸ“š Technologies Used
Backend

FastAPI

Python 3.10

ffmpeg-python

MediaPipe

Librosa

OpenCV

Scikit-learn

Pandas + NumPy

SHAP

Joblib

Frontend

React.js

Custom hooks (useCamera, useAudioRecorder, etc.)

Axios

CSS Modules

ğŸ Running Both Servers
Start backend:
cd backend
.venv\Scripts\activate
uvicorn main:app --reload

Start frontend:
cd frontend
npm start


Frontend automatically connects to:

VITE_BACKEND_URL=http://127.0.0.1:8000
